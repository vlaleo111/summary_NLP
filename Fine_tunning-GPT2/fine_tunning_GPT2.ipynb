{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3577caa9-eb0d-43cb-8909-315703d47927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a1318b-2210-4b9c-9e6c-68f0275ffe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data['Articulos'][idx]\n",
    "        summary = self.data['Resumen'][idx]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            summary,\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'labels': inputs['input_ids'].squeeze()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5516ba61-78f8-4378-92d3-c05620514b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_summary_dataset(tokenizer):\n",
    "    file_path = \"bbc_news_es.csv\"\n",
    "    df = pd.read_csv(file_path)[['Resumen', 'Articulos']]\n",
    "    df = df[list(-(df[\"Resumen\"].duplicated()))]\n",
    "    # df = df[[0, 5]]\n",
    "    # df.columns = ['Resumen', 'Articulos']\n",
    "    # df = df.sample(300, random_state=1)\n",
    "    # df = df.reset_index().drop([\"index\"], axis=1)\n",
    "\n",
    "   # Dividir en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df['Articulos'].tolist(), df['Resumen'].tolist(), test_size=0.1, random_state=1)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_train, y_train, test_size=0.11, random_state=1)\n",
    "    train_data = pd.DataFrame({'Articulos':list(X_train), 'Resumen':list(y_train)})\n",
    "    test_data = pd.DataFrame({'Articulos':list(X_test), 'Resumen':list(y_test)})\n",
    "    valid_data = pd.DataFrame({'Articulos':list(X_valid), 'Resumen':list(y_valid)})\n",
    "\n",
    "    train_dataset = TextDataset(train_data, tokenizer, max_length=1024)\n",
    "    valid_dataset = TextDataset(valid_data, tokenizer, max_length=1024)\n",
    "    test_dataset = TextDataset(test_data, tokenizer, max_length=1024)\n",
    "\n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de1fe24-500e-482d-adae-6cf5617d8a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1295388/2701200775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             eos_token='<endoftext>', pad_token='<pad>')\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_token_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basic/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \"\"\"\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basic/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basic/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basic/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basic/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basic/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basic/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basic/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \"\"\"\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Load model and data\n",
    "#--------------\n",
    "\n",
    "# set model name\n",
    "model_name = \"gpt2-xl\"\n",
    "#seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# load tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, bos_token='<startoftext>', \n",
    "            eos_token='<endoftext>', pad_token='<pad>')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Cargar y dividir el dataset\n",
    "train_dataset, valid_dataset, test_dataset = load_summary_dataset(tokenizer)\n",
    "\n",
    "# Argumentos de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='results',\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=10,\n",
    "    save_strategy='epoch',\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='logs'\n",
    ")\n",
    "\n",
    "# Collator de datos para el modelado de lenguaje\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04bef916-aafa-41d9-9508-b848464c53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar el modelo preentrenado y el tokenizer\n",
    "model_name = 'DeepESP/gpt2-spanish'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Cargar y dividir el dataset en conjuntos de entrenamiento y prueba\n",
    "train_dataset, valid_dataset, test_dataset = load_summary_dataset(tokenizer)\n",
    "\n",
    "# Definir los argumentos de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='results',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=10,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='logs'\n",
    ")\n",
    "\n",
    "# Definir el entrenador\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a7ac113-04b6-4394-93b4-fb0237d6e420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='4590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  25/4590 00:42 < 2:21:58, 0.54 it/s, Epoch 0.05/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.983200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.756700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1295618/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/basic/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m         )\n\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/basic/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1941\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1943\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1944\u001b[0m                 ):\n\u001b[1;32m   1945\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910857b-49e5-41af-a650-2e18ad62516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especifica la ruta de destino donde guardar el modelo y el tokenizer\n",
    "ruta_destino = 'GPT_esp_summary_v4'\n",
    "\n",
    "# Guarda el modelo y el tokenizer en la ruta de destino\n",
    "model.save_pretrained(ruta_destino)\n",
    "tokenizer.save_pretrained(ruta_destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e32d810-4e37-4ca8-af79-17c72b50e01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resumen</th>\n",
       "      <th>Articulos</th>\n",
       "      <th>len_articulo</th>\n",
       "      <th>len_resum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La aerolínea alemana Lufthansa puede demandar ...</td>\n",
       "      <td>Lufthansa puede demandar por la visita de Bush...</td>\n",
       "      <td>1969</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cualquier impuesto sólo se aplicaría después d...</td>\n",
       "      <td>La UE pretende alimentar la ayuda al desarroll...</td>\n",
       "      <td>2503</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los analistas dijeron que las cifras de Ifo y ...</td>\n",
       "      <td>La confianza de las empresas alemanas se desli...</td>\n",
       "      <td>2433</td>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La FAO ha instado a la Organización Mundial de...</td>\n",
       "      <td>La FAO advierte sobre el impacto de las subven...</td>\n",
       "      <td>2340</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dijo: \"Ningún país puede desarrollarse sobre l...</td>\n",
       "      <td>India busca impulsar la construcción India ha ...</td>\n",
       "      <td>2977</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>La Sra. Druyun mantuvo conversaciones con el S...</td>\n",
       "      <td>Ex director de Boeing recibe pena de cárcel Un...</td>\n",
       "      <td>2807</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>Verizon ha ganado una batalla de adquisición p...</td>\n",
       "      <td>Verizon'sella la adquisición de MCI' Verizon h...</td>\n",
       "      <td>2275</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>El índice de gasto en consumo de la universida...</td>\n",
       "      <td>Los datos estadounidenses provocan preocupació...</td>\n",
       "      <td>3094</td>\n",
       "      <td>1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>La petrolera rusa Yukos ha demandado a cuatro ...</td>\n",
       "      <td>Yukos demanda a cuatro empresas por 20 mil mil...</td>\n",
       "      <td>2906</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>El crecimiento económico de EE.UU. se aceleró ...</td>\n",
       "      <td>El gasto de los consumidores aumenta el crecim...</td>\n",
       "      <td>2678</td>\n",
       "      <td>1158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1147 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Resumen  \\\n",
       "0     La aerolínea alemana Lufthansa puede demandar ...   \n",
       "1     Cualquier impuesto sólo se aplicaría después d...   \n",
       "2     Los analistas dijeron que las cifras de Ifo y ...   \n",
       "3     La FAO ha instado a la Organización Mundial de...   \n",
       "4     Dijo: \"Ningún país puede desarrollarse sobre l...   \n",
       "...                                                 ...   \n",
       "1178  La Sra. Druyun mantuvo conversaciones con el S...   \n",
       "1179  Verizon ha ganado una batalla de adquisición p...   \n",
       "1180  El índice de gasto en consumo de la universida...   \n",
       "1181  La petrolera rusa Yukos ha demandado a cuatro ...   \n",
       "1182  El crecimiento económico de EE.UU. se aceleró ...   \n",
       "\n",
       "                                              Articulos  len_articulo  \\\n",
       "0     Lufthansa puede demandar por la visita de Bush...          1969   \n",
       "1     La UE pretende alimentar la ayuda al desarroll...          2503   \n",
       "2     La confianza de las empresas alemanas se desli...          2433   \n",
       "3     La FAO advierte sobre el impacto de las subven...          2340   \n",
       "4     India busca impulsar la construcción India ha ...          2977   \n",
       "...                                                 ...           ...   \n",
       "1178  Ex director de Boeing recibe pena de cárcel Un...          2807   \n",
       "1179  Verizon'sella la adquisición de MCI' Verizon h...          2275   \n",
       "1180  Los datos estadounidenses provocan preocupació...          3094   \n",
       "1181  Yukos demanda a cuatro empresas por 20 mil mil...          2906   \n",
       "1182  El gasto de los consumidores aumenta el crecim...          2678   \n",
       "\n",
       "      len_resum  \n",
       "0          1025  \n",
       "1          1068  \n",
       "2           919  \n",
       "3           879  \n",
       "4          1141  \n",
       "...         ...  \n",
       "1178       1251  \n",
       "1179        878  \n",
       "1180       1302  \n",
       "1181       1247  \n",
       "1182       1158  \n",
       "\n",
       "[1147 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = \"bbc_news_es.csv\"\n",
    "df = pd.read_csv(file_path)[['Resumen', 'Articulos']]\n",
    "df = df[list(-(df[\"Resumen\"].duplicated()))]\n",
    "\n",
    "df['len_articulo'] = [len(i) for i in list(df['Articulos'])]\n",
    "df['len_resum'] = [len(i) for i in list(df['Resumen'])]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee41ee04-2484-41a3-845d-9ff22e87db8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La UE pretende alimentar la ayuda al desarrollo Los ministros de finanzas de la Unión Europea se reúnen el jueves para debatir propuestas, incluido un impuesto sobre el combustible para aviones, para impulsar la ayuda al desarrollo para las naciones más pobres. Los responsables políticos van a pedir un informe sobre cómo se puede recaudar más dinero para el desarrollo, dijo la UE. Los países más ricos del mundo han dicho que quieren aumentar la cantidad de ayuda que dan a 0. 7% de su renta nacional bruta anual para 2015.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Cargar el modelo preentrenado y el tokenizer\n",
    "ruta_modelo_guardado = 'GPT_esp_summary'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = GPT2LMHeadModel.from_pretrained(ruta_modelo_guardado).to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(ruta_modelo_guardado)\n",
    "\n",
    "# Función para generar resúmenes\n",
    "def generate_summary(text):\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=True, return_tensors='pt').to(device)\n",
    "    output = model.generate(input_ids, max_length=100, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Texto de entrada para resumir\n",
    "input_text = 'La UE pretende alimentar la ayuda al desarrollo Los ministros de finanzas de la Unión Europea se reúnen el jueves para debatir propuestas, incluido un impuesto sobre el combustible para aviones, para impulsar la ayuda al desarrollo para las naciones más pobres. Los responsables políticos van a pedir un informe sobre cómo se puede recaudar más dinero para el desarrollo, dijo la UE. Los países más ricos del mundo han dicho que quieren aumentar la cantidad de ayuda que dan a 0. 7% de su renta nacional bruta anual para 2015'\n",
    "\n",
    "# Generar el resumen\n",
    "summary = generate_summary(input_text)\n",
    "\n",
    "# Imprimir el resumen generado\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f4d32b9-4976-4b9d-9599-7f9f9aee23c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La UE pretende alimentar la ayuda al desarrollo Los ministros de finanzas de la Unión Europea se reúnen el jueves para debatir propuestas, incluido un impuesto sobre el combustible para aviones, para impulsar la ayuda al desarrollo para las naciones más pobres. Los responsables políticos van a pedir un informe sobre cómo se puede recaudar más dinero para el desarrollo, dijo la UE. Los países más ricos del mundo han dicho que quieren aumentar la cantidad de ayuda que dan a 0. 7% de su renta nacional bruta anual para 2015.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Cargar el modelo preentrenado y el tokenizer\n",
    "ruta_modelo_guardado = 'GPT_esp_summary_v2'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = GPT2LMHeadModel.from_pretrained(ruta_modelo_guardado).to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(ruta_modelo_guardado)\n",
    "\n",
    "# Función para generar resúmenes\n",
    "def generate_summary(text):\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=True, return_tensors='pt').to(device)\n",
    "    output = model.generate(input_ids, max_length=100, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Texto de entrada para resumir\n",
    "input_text = 'La UE pretende alimentar la ayuda al desarrollo Los ministros de finanzas de la Unión Europea se reúnen el jueves para debatir propuestas, incluido un impuesto sobre el combustible para aviones, para impulsar la ayuda al desarrollo para las naciones más pobres. Los responsables políticos van a pedir un informe sobre cómo se puede recaudar más dinero para el desarrollo, dijo la UE. Los países más ricos del mundo han dicho que quieren aumentar la cantidad de ayuda que dan a 0. 7% de su renta nacional bruta anual para 2015'\n",
    "\n",
    "# Generar el resumen\n",
    "summary = generate_summary(input_text)\n",
    "\n",
    "# Imprimir el resumen generado\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52448249-3d8b-4002-84ea-f9b1e394b9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La UE pretende alimentar la ayuda al desarrollo Los ministros de finanzas de la Unión Europea se reúnen el jueves para debatir propuestas, incluido un impuesto sobre el combustible para aviones, para impulsar la ayuda al desarrollo para las naciones más pobres. Los responsables políticos van a pedir un informe sobre cómo se puede recaudar más dinero para el desarrollo, dijo la UE. Los países más ricos del mundo han dicho que quieren aumentar la cantidad de ayuda que dan a 0. 7% de su renta nacional bruta anual para 2015.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Cargar el modelo preentrenado y el tokenizer\n",
    "ruta_modelo_guardado = 'GPT_esp_summary_v4'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = GPT2LMHeadModel.from_pretrained(ruta_modelo_guardado).to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(ruta_modelo_guardado)\n",
    "\n",
    "# Función para generar resúmenes\n",
    "def generate_summary(text):\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=True, return_tensors='pt').to(device)\n",
    "    output = model.generate(input_ids, max_length=100, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Texto de entrada para resumir\n",
    "input_text = 'La UE pretende alimentar la ayuda al desarrollo Los ministros de finanzas de la Unión Europea se reúnen el jueves para debatir propuestas, incluido un impuesto sobre el combustible para aviones, para impulsar la ayuda al desarrollo para las naciones más pobres. Los responsables políticos van a pedir un informe sobre cómo se puede recaudar más dinero para el desarrollo, dijo la UE. Los países más ricos del mundo han dicho que quieren aumentar la cantidad de ayuda que dan a 0. 7% de su renta nacional bruta anual para 2015'\n",
    "\n",
    "# Generar el resumen\n",
    "summary = generate_summary(input_text)\n",
    "\n",
    "# Imprimir el resumen generado\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613f3152-0e65-4267-a198-67b9acb8fe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Que día es hoy? Es lunes creo que es el día más feliz de mi vida y no puedo pensar en otra cosa que hacer\", dijo el Sr. Dowell.. El Sr. Dowell dijo que el gobierno estaba considerando la posibilidad de reducir el número de personas afectadas por el tsunami.. El Sr. Dowell dijo que el gobierno estaba considerando la posibilidad de reducir el número de personas afectadas por el tsunami.. El Sr. Dowell dijo que el gobierno estaba considerando la posibilidad de\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Cargar el modelo preentrenado y el tokenizer\n",
    "ruta_modelo_guardado = 'GPT_esp_summary_v4'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = GPT2LMHeadModel.from_pretrained(ruta_modelo_guardado).to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(ruta_modelo_guardado)\n",
    "\n",
    "# Función para generar resúmenes\n",
    "def generate_summary(text):\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=True, return_tensors='pt').to(device)\n",
    "    output = model.generate(input_ids, max_length=100, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Texto de entrada para resumir\n",
    "input_text = 'Que día es hoy? Es lunes creo'\n",
    "# 'El Ministerio de Transportes y Comunicaciones a través de la Resolución directoral 40-2021, publicada hoy en el Diario El Peruano, decidió ampliar la vigencia de los certificados de salud para el otorgamiento de las licencias. Se extiende hasta el 31 de julio, las licencias de conducir de la clase B y los certificados de salud para el otorgamiento de las licencias de conducir de la clase B, cuyo vencimiento se haya producido desde el 1 de enero de 2020 hasta el 30 de julio'\n",
    "\n",
    "# Generar el resumen\n",
    "summary = generate_summary(input_text)\n",
    "\n",
    "# Imprimir el resumen generado\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e94dc-252d-4035-848e-693e5005da82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
